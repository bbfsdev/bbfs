How to use distributed file crawler
-----------------------------------

Prerequisites:
Each server you have files on have to have the following:
1) Ruby 1.9.2
2) NET-SSH and NET-SFTP gems installed.

Preparing configuration file:
Note1: The pattern is not a regular expression; instead it follows rules similar
       to shell filename globbing
       Link: http://www.ruby-doc.org/core/classes/File.html#M000001
Note2: If private/public keys are used then password field can be omitted.
       If in addition usernames are the same on the source and target machines
       then username field may also be omitted
Example:
server
  name: localhost
  directories:
    hd1:+:/usr/home/bin/*.(mp3|mov)
    hd1:-:/usr/home/bin/kuku/*
    hd1:-:/usr/home/bin/*dont_index/*
  server
    name: large_server_1
    username: kuku_crawl
    password: kaka
    port: 2222
    directories:
      hd1:+:/usr/home/bin/*.(mp3|mov)
      hd1:-:/usr/home/bin/kuku/*
      hd1:-:/usr/home/bin/*dont_index/*

Running the crawler:
ruby crawler.rb <config file>


For developers
--------------
To be corresponded with Ruby 1.9.2 all required files  with paths relative to current
directory need to have a "./" before it. e.g.:
require 'crawler' have to be require './crawler'

Pull request test. Fixing this code.